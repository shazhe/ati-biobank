Automatically generated by Mendeley Desktop 1.16.1
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Tucci2013,
abstract = {This is a purely pedagogical paper with no new results. The goal of the paper is to give a fairly self-contained introduction to Judea Pearl's do-calculus, including proofs of his 3 rules.},
archivePrefix = {arXiv},
arxivId = {1305.5506},
author = {Tucci, Robert R.},
eprint = {1305.5506},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Tucci - 2013 - Introduction to Judea Pearl's Do-Calculus(2).pdf:pdf},
journal = {CoRR},
title = {{Introduction to Judea Pearl's Do-Calculus}},
url = {http://arxiv.org/abs/1305.5506},
year = {2013}
}
@article{Gelman2010,
abstract = {We review some approaches and philosophies of causal inference coming from sociology, economics, computer science, cognitive science, and statistics},
archivePrefix = {arXiv},
arxivId = {1003.2619},
author = {Gelman, Andrew},
doi = {10.1086/662659},
eprint = {1003.2619},
issn = {00029602},
journal = {American Journal of Sociology},
number = {3},
pages = {955--966},
title = {{Causality and Statistical Learning}},
url = {http://arxiv.org/abs/1003.2619},
volume = {117},
year = {2010}
}
@inproceedings{Pearl2012b,
abstract = {The do-calculus was developed in 1995 to facilitate the identification of causal effects in non-parametric models. The completeness proofs of [Huang and Valtorta, 2006] and [Shpitser and Pearl, 2006] and the graphical criteria of [Tian and Shpitser, 2010] have laid this identification problem to rest. Recent explorations unveil the usefulness of the do-calculus in three additional areas: mediation analysis [Pearl, 2012], transportability [Pearl and Bareinboim, 2011] and metasynthesis. Meta-synthesis (freshly coined) is the task of fusing empirical results from several diverse studies, conducted on heterogeneous populations and under different conditions, so as to synthesize an estimate of a causal relation in some target environment, potentially different from those under study. The talk surveys these results with emphasis on the challenges posed by meta-synthesis. For background material, see http://bayes.cs.ucla.edu/csl{\_}papers.html},
address = {Catalina},
archivePrefix = {arXiv},
arxivId = {1210.4852},
author = {Pearl, Judea},
booktitle = {Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial Intelligence},
editor = {de Freitas, Nando and Murphy, Kevin},
eprint = {1210.4852},
file = {:Users/anavarro/Documents/pearl2012.pdf:pdf},
isbn = {9780974903989},
issn = {0000-0000},
number = {August},
pages = {4--11},
title = {{The Do -Calculus Revisited}},
year = {2012}
}
@techreport{Navarro2016,
abstract = {Circular variables arise in a multitude of data-modelling contexts ranging from robots to social sciences. To correctly predict and analyse circular data, the field of circular and directional statistics has developed a range of MCMC methods for low-dimensional problems and small to medium-sized datasets. In this paper, we extend the toolbox of circular statistics to higher dimensions as a step towards bringing this field and probabilistic machine learning together. To achieve this task, we introduce a Gaussian Process analogue for circular variables and outline how to perform variational inference for this model. We demonstrate how this model naturally occurs in the contexts of regression and latent variable modelling and present experimental results where this model overperforms standard probabilistic machine learning approaches that do not account for the topological properties of circular variables.},
archivePrefix = {arXiv},
arxivId = {1602.05003},
author = {Navarro, Alexandre K. W. and Turner, Richard E. and Frellsen, Jes},
booktitle = {arXiv preprint},
eprint = {1602.05003},
title = {{The Multivariate Generalised von Mises: Inference and applications}},
url = {http://arxiv.org/abs/1602.05003},
year = {2016}
}
@inproceedings{Zhang2007a,
address = {San Juan},
author = {Zhang, Jiji},
booktitle = {Eleventh International Conference on Artificial Intelligence and Statistics},
editor = {Meila, Marina and Shen, Xiaotong},
file = {:Users/anavarro/Documents/zhang07a.pdf:pdf},
issn = {15324435},
pages = {667--674},
title = {{Generalized Do-Calculus with Testable Causal Assumptions}},
url = {http://www.jmlr.org/proceedings/papers/v2/},
year = {2007}
}
@article{Douaud2013,
abstract = {Is it possible to prevent atrophy of key brain regions related to cognitive decline and Alzheimer's disease (AD)? One approach is to modify nongenetic risk factors, for instance by lowering elevated plasma homocysteine using B vitamins. In an initial, randomized controlled study on elderly subjects with increased dementia risk (mild cognitive impairment according to 2004 Petersen criteria), we showed that high-dose B-vitamin treatment (folic acid 0.8 mg, vitamin B6 20 mg, vitamin B12 0.5 mg) slowed shrinkage of the whole brain volume over 2 y. Here, we go further by demonstrating that B-vitamin treatment reduces, by as much as seven fold, the cerebral atrophy in those gray matter (GM) regions specifically vulnerable to the AD process, including the medial temporal lobe. In the placebo group, higher homocysteine levels at baseline are associated with faster GM atrophy, but this deleterious effect is largely prevented by B-vitamin treatment. We additionally show that the beneficial effect of B vitamins is confined to participants with high homocysteine (above the median, 11 µmol/L) and that, in these participants, a causal Bayesian network analysis indicates the following chain of events: B vitamins lower homocysteine, which directly leads to a decrease in GM atrophy, thereby slowing cognitive decline. Our results show that B-vitamin supplementation can slow the atrophy of specific brain regions that are a key component of the AD process and that are associated with cognitive decline. Further B-vitamin supplementation trials focusing on elderly subjets with high homocysteine levels are warranted to see if progression to dementia can be prevented.},
author = {Douaud, Gwena{\"{e}}lle and Refsum, Helga and de Jager, Celeste and Jacoby, Robin and Nichols, Thomas E. and Smith, Stephen M. and Smith, David},
doi = {10.1073/pnas.1301816110},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Douaud et al. - 2013 - Preventing Alzheimer's disease-related gray matter atrophy by B-vitamin treatment.pdf:pdf},
isbn = {0027-8424},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Alzheimer Disease,Alzheimer Disease: complications,Bayes Theorem,Computer-Assisted,England,Hippocampus,Hippocampus: drug effects,Hippocampus: pathology,Homocysteine,Homocysteine: blood,Humans,Image Processing,Linear Models,Longitudinal Studies,Magnetic Resonance Imaging,Nerve Degeneration,Nerve Degeneration: etiology,Nerve Degeneration: pathology,Nerve Degeneration: prevention {\&} control,Temporal Lobe,Temporal Lobe: drug effects,Temporal Lobe: pathology,Vitamin B Complex,Vitamin B Complex: pharmacology,Vitamin B Complex: therapeutic use},
number = {23},
pages = {9523--8},
pmid = {23690582},
title = {{Preventing Alzheimer's disease-related gray matter atrophy by B-vitamin treatment.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3677457{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {110},
year = {2013}
}
@inproceedings{Zhang2007,
address = {San Juan},
author = {Zhang, Jiji},
booktitle = {Eleventh International Conference on Artificial Intelligence and Statistics},
editor = {Meila, Marina and Shen, Xiaotong},
file = {:Users/anavarro/Documents/zhang2007a.pdf:pdf},
issn = {15324435},
pages = {667--674},
title = {{Generalized Do-Calculus with Testable Causal Assumptions}},
url = {http://www.jmlr.org/proceedings/papers/v2/},
year = {2007}
}
@article{Peng2009,
abstract = {In this paper, we propose a computationally efficient approach -space(Sparse PArtial Correlation Estimation)- for selecting non-zero partial correlations under the high-dimension-low-sample-size setting. This method assumes the overall sparsity of the partial correlation matrix and employs sparse regression techniques for model fitting. We illustrate the performance of space by extensive simulation studies. It is shown that space performs well in both non-zero partial correlation selection and the identification of hub variables, and also outperforms two existing methods. We then apply space to a microarray breast cancer data set and identify a set of hub genes which may provide important insights on genetic regulatory networks. Finally, we prove that, under a set of suitable assumptions, the proposed procedure is asymptotically consistent in terms of model selection and parameter estimation.},
archivePrefix = {arXiv},
arxivId = {0811.4463},
author = {Peng, Jie and Wang, Pei and Zhou, Nengfeng and Zhu, Ji},
doi = {10.1198/jasa.2009.0126},
eprint = {0811.4463},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Peng et al. - 2009 - Partial Correlation Estimation by Joint Sparse Regression Models.pdf:pdf},
isbn = {0162-1459},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {concentration network,genetic regulatory network,high-dimension-low-sample-size,lasso,shooting},
number = {486},
pages = {735--746},
pmid = {19881892},
title = {{Partial Correlation Estimation by Joint Sparse Regression Models.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2770199{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {104},
year = {2009}
}
@article{Gage2016,
annote = {A bit too biological...},
author = {Gage, Suzanne H. and {Davey Smith}, George and Ware, Jennifer J. and Flint, Jonathan and Munaf{\`{o}}, Marcus R.},
editor = {Gibson, Greg},
issn = {1553-7404},
journal = {PLOS Genetics},
month = {feb},
number = {2},
pages = {e1005765},
publisher = {Public Library of Science},
title = {{G = E: What GWAS Can Tell Us about the Environment}},
url = {http://dx.doi.org/10.1371/journal.pgen.1005765},
volume = {12},
year = {2016}
}
@article{Ramsey2006,
abstract = {Most causal inference algorithms in the literature (e.g., Pearl (2000), Spirtes et al. (2000), Heckerman et al. (1999)) exploit an assumption usually referred to as the causal Faithfulness or Stability condition. In this paper, we highlight two components of the condition used in constraint-based algorithms, which we call "Adjacency-Faithfulness" and "Orientation-Faithfulness". We point out that assuming Adjacency-Faithfulness is true, it is in principle possible to test the validity of Orientation-Faithfulness. Based on this observation, we explore the consequence of making only the Adjacency-Faithfulness assumption. We show that the familiar PC algorithm has to be modified to be (asymptotically) correct under the weaker, Adjacency-Faithfulness assumption. Roughly the modified algorithm, called Conservative PC (CPC), checks whether Orientation-Faithfulness holds in the orientation phase, and if not, avoids drawing certain causal conclusions the PC algorithm would draw. However, if the stronger, standard causal Faithfulness condition actually obtains, the CPC algorithm is shown to output the same pattern as the PC algorithm does in the large sample limit. We also present a simulation study showing that the CPC algorithm runs almost as fast as the PC algorithm, and outputs significantly fewer false causal arrowheads than the PC algorithm does on realistic sample sizes. We end our paper by discussing how score-based algorithms such as GES perform when the Adjacency-Faithfulness but not the standard causal Faithfulness condition holds, and how to extend our work to the FCI algorithm, which allows for the possibility of latent variables.},
archivePrefix = {arXiv},
arxivId = {1206.6843},
author = {Ramsey, Joseph and Zhang, Jiji and Spirtes, Peter L.},
eprint = {1206.6843},
file = {:Users/anavarro/Documents/ramsay2006.pdf:pdf},
isbn = {0-9749039-2-2},
journal = {Proceedings of the Twenty-Second Conference on Uncertainty in Artificial Intelligence},
month = {jun},
pages = {401--408},
title = {{Adjacency-Faithfulness and Conservative Causal Inference}},
url = {http://arxiv.org/abs/1206.6843},
year = {2006}
}
@article{Smith2012,
abstract = {"FMRI connectivity" encompasses many areas of research, including resting-state networks, biophysical modelling of task-FMRI data and bottom-up simulation of multiple individual neurons interacting with each other. In this brief paper I discuss several outstanding areas that I believe will see exciting developments in the next few years, in particular concentrating on how I think the currently separate approaches will increasingly need to take advantage of each others' respective complementarities. {\textcopyright} 2012 Elsevier Inc.},
author = {Smith, Stephen M.},
doi = {10.1016/j.neuroimage.2012.01.022},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Smith - 2012 - The future of FMRI connectivity.pdf:pdf},
isbn = {1095-9572},
issn = {10538119},
journal = {NeuroImage},
keywords = {Bayes nets,Causality,DCM,Dual-regression,Effective connectivity,FMRI,Functional connectivity,ICA,Resting-state networks,SEM},
number = {2},
pages = {1257--1266},
pmid = {22248579},
publisher = {Elsevier Inc.},
title = {{The future of FMRI connectivity}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2012.01.022},
volume = {62},
year = {2012}
}
@article{Jenkinson2001,
abstract = {This report gives a basic introduction to the ideas and theory behind ICA as applied to FMRI. It also considers the initial PCA dimensionality reduction, and discusses the orthogonality of various signals.},
author = {Jenkinson, Mark and Beckmann, Christian F.},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Jenkinson, Beckmann - 2001 - ICA in FMRI A Basic Introduction.pdf:pdf},
journal = {FMRIB Technical Report TR01MJ2},
pages = {7--9},
title = {{ICA in FMRI: A Basic Introduction}},
year = {2001}
}
@article{McIntosh1994a,
abstract = {The analysis of brain imaging data has recently focused on the examination of the covariances of activity among neural regions during different behaviors. We present some of the theoretical and technical issues surrounding one of these covariance-based methods: structural equation modeling. In structural equation modeling, connections between brain areas are based on known neuroanatomy, and the interregional covariances of activity are used to calculate path coefficients representing the magnitude of the influence of each directional path. The logic behind the use of structural equation modeling stems from the suggestion that brain function is the result of changes in the covariances of activity among neural elements. The technical foundations for neural structural equation models are presented, emphasizing the ability to make inferential comparisons to evaluate the experimental changes in path coefficients. Simulated data sets were used to test the effects of omitted regions and omitted connections. The results suggested that structural modeling algorithms can give hints as to possible external influences and missing paths, but that the final decision as to model modifications requires the guidance of the researcher. The utility of anatomically based models to distinguish between the direct effect of one region on another, and indirect effects of darkness or patterned light on the metabolic activity in the rat visual system. The anatomical framework for the structural equation models revealed that the total impact of ascending thalamocortical influences was modified by corticocortical interactions. Extensions of structural equation modeling to human brain imaging experiments are presented. We conclude by suggesting that neural covariances may be a more accurate way to examine the dynamic functional organization of the central nervous system.},
author = {McIntosh, Anthony Randal and Gonzalez-Lima, Francisco},
doi = {10.1002/hbm.460020104},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/McIntosh, Gonzalez-Lima - 1994 - Structural equation modeling and its application to network analysis in functional brain imaging.pdf:pdf},
issn = {10659471},
journal = {Hbm},
keywords = {2-deoxyglucose,human,neural pathway,neural systems,path analysis,positron emission tomography,rat,regional cerebral blood flow,visual system},
number = {1-2},
pages = {2--22},
title = {{Structural equation modeling and its application to network analysis in functional brain imaging}},
url = {http://doi.wiley.com/10.1002/hbm.460020104},
volume = {2},
year = {1994}
}
@article{Shimizu2006a,
abstract = {In recent years; several methods have been proposed for the discovery of causal structure from non-experimental data. Such methods make various assumptions on the data generating process to facilitate its identification from purely observational data. Continuing this line of research; we show how to discover the complete causal structure of continuous-valued data; under the assump- tions that (a) the data generating process is linear; (b) there are no unobserved confounders; and (c) disturbance variables have non-Gaussian distributions of non-zero variances. The solution relies on the use of the statistical method known as independent component analysis; and does not require any pre-specified time-ordering of the variables. We provide a complete Matlab package for per- forming this LiNGAM analysis (short for Linear Non-Gaussian Acyclic Model); and demonstrate the effectiveness of the method using artificially generated data and real-world data.},
author = {Shimizu, Shohei and Hoyer, Patrik O. and Hyv{\"{a}}rinen, Aapo and Kerminen, Antti},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Shimizu et al. - 2006 - A linear non-Gaussian acyclic model for causal discovery.pdf:pdf},
isbn = {1532-4435},
issn = {10985522},
journal = {The Journal of Machine Learning Research},
keywords = {Causal Inference,LiNGAM,causal discovery,directed acyclic,graph,independent component analysis,non-experimental data,non-gaussianity},
mendeley-tags = {Causal Inference,LiNGAM},
pages = {2003--2030},
pmid = {21115720},
title = {{A linear non-Gaussian acyclic model for causal discovery}},
url = {http://dl.acm.org/citation.cfm?id=1248619},
volume = {7},
year = {2006}
}
@article{Penny2004b,
abstract = {The brain appears to adhere to two fundamental principles of functional organisation, functional integration and functional specialisation, where the integration within and among specialised areas is mediated by effective connectivity. In this paper, we review two different approaches to modelling effective connectivity from fMRI data, structural equation models (SEMs) and dynamic causal models (DCMs). In common to both approaches are model comparison frameworks in which inferences can be made about effective connectivity per se and about how that connectivity can be changed by perceptual or cognitive set. Underlying the two approaches, however, are two very different generative models. In DCM, a distinction is made between the 'neuronal level' and the 'hemodynamic level'. Experimental inputs cause changes in effective connectivity expressed at the level of neurodynamics, which in turn cause changes in the observed hemodynamics. In SEM, changes in effective connectivity lead directly to changes in the covariance structure of the observed hemodynamics. Because changes in effective connectivity in the brain occur at a neuronal level DCM is the preferred model for fMRI data. This review focuses on the underlying assumptions and limitations of each model and demonstrates their application to data from a study of attention to visual motion. ?? 2004 Elsevier Inc. All rights reserved.},
author = {Penny, W. D. and Stephan, K. E. and Mechelli, A. and Friston, K. J.},
doi = {10.1016/j.neuroimage.2004.07.041},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Penny et al. - 2004 - Modelling functional integration A comparison of structural equation and dynamic causal models.pdf:pdf},
isbn = {1053-8119 (Print){\$}\backslash{\$}n1053-8119 (Linking)},
issn = {10538119},
journal = {NeuroImage},
keywords = {Dynamic causal model,Functional integration,Structural equation},
number = {SUPPL. 1},
pages = {264--274},
pmid = {15501096},
title = {{Modelling functional integration: A comparison of structural equation and dynamic causal models}},
volume = {23},
year = {2004}
}
@article{Yin2008,
author = {Yin, Jianxin and Zhou, Y and Wang, Changzhang and He, P},
file = {:Users/anavarro/Documents/yin08a.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {causal network,local structural learning,partial orientation},
pages = {93--105},
title = {{Partial orientation and local structural learning of causal networks for prediction.}},
url = {http://msn.mtome.com/Publications/CiML/CiML-v2-book.pdf{\#}page=99},
year = {2008}
}
@article{Granger1969a,
author = {Granger, C. W. J.},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Granger - 1969 - Investigating Causal Relations by Econometric Models and Cross-spectral Methods.pdf:pdf},
journal = {Econometrica},
number = {3},
pages = {424--438},
title = {{Investigating Causal Relations by Econometric Models and Cross-spectral Methods}},
volume = {37},
year = {1969}
}
@article{Penny2004c,
abstract = {This article describes the use of Bayes factors for comparing dynamic causal models (DCMs). DCMs are used to make inferences about effective connectivity from functional magnetic resonance imaging (fMRI) data. These inferences, however, are contingent upon assumptions about model structure, that is, the connectivity pattern between the regions included in the model. Given the current lack of detailed knowledge on anatomical connectivity in the human brain, there are often considerable degrees of freedom when defining the connectional structure of DCMs. In addition, many plausible scientific hypotheses may exist about which connections are changed by experimental manipulation, and a formal procedure for directly comparing these competing hypotheses is highly desirable. In this article, we show how Bayes factors can be used to guide choices about model structure, both concerning the intrinsic connectivity pattern and the contextual modulation of individual connections. The combined use of Bayes factors and DCM thus allows one to evaluate competing scientific theories about the architecture of large-scale neural networks and the neuronal interactions that mediate perception and cognition. {\textcopyright} 2004 Elsevier Inc. All rights reserved.},
author = {Penny, W. D. and Stephan, K. E. and Mechelli, A. and Friston, K. J.},
doi = {10.1016/j.neuroimage.2004.03.026},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Penny et al. - 2004 - Comparing dynamic causal models.pdf:pdf},
isbn = {1053-8119 (Print)$\backslash$n1053-8119 (Linking)},
issn = {10538119},
journal = {NeuroImage},
keywords = {Bayes factors,Dynamic causal models,fMRI},
number = {3},
pages = {1157--1172},
pmid = {15219588},
title = {{Comparing dynamic causal models}},
volume = {22},
year = {2004}
}
@article{Stephan2010a,
abstract = {Dynamic causal modeling (DCM) is a generic Bayesian framework for inferring hidden neuronal states from measurements of brain activity. It provides posterior estimates of neurobiologically interpretable quantities such as the effective strength of synaptic connections among neuronal populations and their context-dependent modulation. DCM is increasingly used in the analysis of a wide range of neuroimaging and electrophysiological data. Given the relative complexity of DCM, compared to conventional analysis techniques, a good knowledge of its theoretical foundations is needed to avoid pitfalls in its application and interpretation of results. By providing good practice recommendations for DCM, in the form of ten simple rules, we hope that this article serves as a helpful tutorial for the growing community of DCM users. ?? 2009 Elsevier Inc. All rights reserved.},
author = {Stephan, K. E. and Penny, W. D. and Moran, R. J. and den Ouden, H. E. M. and Daunizeau, J. and Friston, K. J.},
doi = {10.1016/j.neuroimage.2009.11.015},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Stephan et al. - 2010 - Ten simple rules for dynamic causal modeling.pdf:pdf},
isbn = {1095-9572 (Electronic)$\backslash$n1053-8119 (Linking)},
issn = {10538119},
journal = {NeuroImage},
keywords = {BMS,Bayes factor,Bayesian model selection,DCM,EEG,Effective connectivity,MEG,Model comparison,Model evidence,Nonlinear dynamics,Synaptic plasticity,fMRI},
number = {4},
pages = {3099--3109},
pmid = {19914382},
publisher = {Elsevier Inc.},
title = {{Ten simple rules for dynamic causal modeling}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2009.11.015},
volume = {49},
year = {2010}
}
@article{Friston2003a,
abstract = {In this paper we present an approach to the identification of nonlinear input-state-output systems. By using a bilinear approximation to the dynamics of interactions among states, the parameters of the implicit causal model reduce to three sets. These comprise (1) parameters that mediate the influence of extrinsic inputs on the states, (2) parameters that mediate intrinsic coupling among the states, and (3) [bilinear] parameters that allow the inputs to modulate that coupling. Identification proceeds in a Bayesian framework given known, deterministic inputs and the observed responses of the system. We developed this approach for the analysis of effective connectivity using experimentally designed inputs and fMRI responses. In this context, the coupling parameters correspond to effective connectivity and the bilinear parameters reflect the changes in connectivity induced by inputs. The ensuing framework allows one to characterise fMRI experiments, conceptually, as an experimental manipulation of integration among brain regions (by contextual or trial-free inputs, like time or attentional set) that is revealed using evoked responses (to perturbations or trial-bound inputs, like stimuli). As with previous analyses of effective connectivity, the focus is on experimentally induced changes in coupling (cf., psychophysiologic interactions). However, unlike previous approaches in neuroimaging, the causal model ascribes responses to designed deterministic inputs, as opposed to treating inputs as unknown and stochastic. ?? 2003 Elsevier Science (USA). All rights reserved.},
author = {Friston, K. J. and Harrison, L. and Penny, W. D.},
doi = {10.1016/S1053-8119(03)00202-7},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Friston, Harrison, Penny - 2003 - Dynamic causal modelling.pdf:pdf},
isbn = {9780122648410},
issn = {10538119},
journal = {NeuroImage},
keywords = {Bilinear model,Effective connectivity,Functional neuroimaging,Hemodynamic response function,Nonlinear system identification,fMRI},
number = {4},
pages = {1273--1302},
pmid = {12948688},
title = {{Dynamic causal modelling}},
volume = {19},
year = {2003}
}
@book{Pearl2000,
abstract = {Chapter headings: Introduction to Probabilities, Graphs, and Causal Models; A Theory of Inferred Causation; Causal Diagrams and the Identification of Causal Effects; Actions, Plans, and Direct Effects; Causality and Structural Models in Social Science and Economics; Simpson's Paradoxon, Confounding, and Collapsibility; The Logic of Structure-Based Counterfactuals; Imperfect Experiments: Bounding Effects and Counterfactuals; Probability of Causation: Interpretation and Identification; The Actual Cause; Epilogue: The Art and Science of Cause and Effect},
annote = {Might want to read the other shorter and more recent papers first.},
author = {Pearl, Judea},
doi = {citeulike-article-id:3888442},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Pearl - 2000 - Causality Models, Reasoning, and Inference.pdf:pdf},
isbn = {0521773628},
publisher = {Cambridge University Press},
title = {{Causality: Models, Reasoning, and Inference}},
year = {2000}
}
@article{Smith2015,
abstract = {The Human Connectome Project (HCP) 1 is acquiring high-quality in vivo macroscopic-level connectome imaging data from over a thousand healthy adult subjects in an effort to elucidate the neural pathways and networks that underlie brain function and behavior. An overarching aim is to reveal much about what makes us uniquely human and what makes individuals different from each other by understanding how brain networks integrate information through the complex pattern of neural connections. To date, data sets from 500 subjects have been publicly released, including imaging data measuring functional and structural brain connectivity, as well as 280 non-imaging subject measures (SMs), including demographics (age, sex, income, education level, drug use, etc.), psychometrics (IQ, language performance, etc.) and other behavioral measures such as 'rule-breaking behavior' . We sought to relate functional connectomes to behavior in a single integrated analysis. This goes further than simply investigating which SMs correlate with other SMs; we wanted to discover whether any specific patterns of brain connectivity are associated with specific sets of correlated demographics and behavior, as brain-behavior modes of population co-variation. We used resting-state functional magnetic resonance imaging (fMRI) data from 461 HCP subjects, and network modeling tools from FSL (FMRIB Software Library). A population-average brain parcellation was estimated using independent component analysis 2 , yielding 200 distinct brain regions; these constitute the nodes in our network modeling. The functional connections (edges) between these nodes were estimated using Tikhonov-regularized partial correlation, resulting in a 200 × 200 connectome for each subject. These connec-tomes were combined into a single large connectome matrix (con-taining all connectomes from all subjects; Supplementary Fig. 1). Separately, 158 behavioral and demographic non-imaging SMs from the same set of subjects were formed into a subject measure matrix. We regressed potential confounds (including brain size and head motion) out of both matrices. Redundancies among connectomes and SMs were reduced by (separately) keeping just the first 100 principal components of each matrix. A natural choice of method for investigating underlying relation-ships between two sets of variables is canonical correlation analysis (CCA) 3 , a procedure that seeks maximal correlations between com-binations of variables in both sets. Using CCA, we estimated pairs of canonical variates along which sets of SMs and patterns of brain con-nectivity co-vary in a similar way across subjects. We refer to each such pair of variates as a mode of co-variation. Strict tests were applied to avoid over-fitting and false-positive inflation. Statistical significance was determined with a permutation test that accounted for the fam-ily structure of the HCP data 4 . This analysis revealed a single highly significant CCA mode that relates functional connectomes to subject measures (r = 0.87, P {\textless} 10 −5 corrected for multiple comparisons across all modes estimated). These analyses were driven by and report only correlations; inferring and interpreting the (presumably complex and diverse) causalities remains a challenging issue for the future.},
author = {Smith, Stephen M. and Nichols, Thomas E. and Vidaurre, Diego and Winkler, Anderson M. and {J Behrens}, Timothy E. and Glasser, Matthew F. and Ugurbil, Kamil and Barch, Deanna M. and {Van Essen}, David C. and Miller, Karla L.},
doi = {10.1038/nn.4125},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Smith et al. - 2015 - A positive-negative mode of population covariation links brain connectivity, demographics and behavior.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$r1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {September},
pages = {1--7},
pmid = {26414616},
publisher = {Nature Publishing Group},
title = {{A positive-negative mode of population covariation links brain connectivity, demographics and behavior}},
url = {http://dx.doi.org/10.1038/nn.4125},
volume = {18},
year = {2015}
}
@article{Basu2015a,
abstract = {The problem of estimating high-dimensional network models arises naturally in the analysis of many physical, biological and socio-economic systems. Examples include stock price fluctuations in financial markets and gene regulatory networks representing effects of regulators (transcription factors) on regulated genes in genetics. We aim to learn the structure of the network over time employing the framework of Granger causal models under the assumptions of sparsity of its edges and inherent grouping structure among its nodes. We introduce a thresholded variant of the Group Lasso estimator for discovering Granger causal interactions among the nodes of the network. Asymptotic results on the consistency of the new estimation procedure are developed. The performance of the proposed methodology is assessed through an extensive set of simulation studies and comparisons with existing techniques.},
archivePrefix = {arXiv},
arxivId = {1210.3711},
author = {Basu, Sumanta and Shojaie, Ali and Michailidis, George},
eprint = {1210.3711},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Basu, Shojaie, Michailidis - 2015 - Network Granger Causality with Inherent Grouping Structure.pdf:pdf},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {granger causality,group lasso,high dimensional networks,model,panel vector autoregression,thresholding},
pages = {417--453},
title = {{Network Granger Causality with Inherent Grouping Structure}},
url = {http://jmlr.org/papers/v16/basu15a.html},
volume = {16},
year = {2015}
}
@article{Patel2006a,
abstract = {Recent work regarding the analysis of brain imaging data has focused on examining functional and effective connectivity of the brain. We develop a novel descriptive and inferential method to analyze the connectivity of the human brain using functional MRI (fMRI). We assess the relationship between pairs of distinct brain regions by comparing expected joint and marginal probabilities of elevated activity of voxel pairs through a Bayesian paradigm, which allows for the incorporation of previously known anatomical and functional information. We define the relationship between two distinct brain regions by measures of functional connectivity and ascendancy. After assessing the relationship between all pairs of brain voxels, we are able to construct hierarchical functional networks from any given brain region and assess significant functional connectivity and ascendancy in these networks. We illustrate the use of our connectivity analysis using data from an fMRI study of social cooperation among women who played an iterated "Prisoner's Dilemma" game. Our analysis reveals a functional network that includes the amygdala, anterior insula cortex, and anterior cingulate cortex, and another network that includes the ventral striatum, orbitofrontal cortex, and anterior insula. Our method can be used to develop causal brain networks for use with structural equation modeling and dynamic causal models.},
author = {Patel, Rajan S. and Bowman, F. DuBois and Rilling, James K.},
doi = {10.1002/hbm.20182},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Patel, Bowman, Rilling - 2006 - A Bayesian approach to determining connectivity of the human brain.pdf:pdf},
isbn = {1097-0193},
issn = {10659471},
journal = {Human Brain Mapping},
keywords = {Amygdala,Effective connectivity,Functional connectivity,Ventral striatum,fMRI},
number = {3},
pages = {267--276},
pmid = {16092131},
title = {{A Bayesian approach to determining connectivity of the human brain}},
volume = {27},
year = {2006}
}
@incollection{NIPS2000_1856,
abstract = {High dimensional data modeling is difficult mainly because the so-called "curse of dimensionality". We propose a technique called "Gaussianiza- tion" for high dimensional density estimation, which alleviates the curse of dimensionality by exploiting the independence structures in the data. Gaussianization is motivated from recent developments in the statistics literature: projection pursuit, independent component analysis and Gaus- sian mixture models with semi-tied covariances. We propose an iter- ative Gaussianization procedure which converges weakly: at each it- eration, the data is first transformed to the least dependent coordinates and then each coordinate is marginally Gaussianized by univariate tech- niques. Gaussianization offers density estimation sharper than traditional kernel methods and radial basis function methods. Gaussianization can be viewed as efficient solution of nonlinear independent component anal- ysis and high dimensional projection pursuit.},
author = {Chen, Scott Shaobing Saobing and Gopinath, Ramesh A.},
booktitle = {Advances in Neural Information Processing Systems 13},
editor = {Leen, T K and Dietterich, T G and Tresp, V},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Chen, Gopinath - 2001 - Gaussianization.pdf:pdf},
pages = {423--429},
publisher = {MIT Press},
title = {{Gaussianization}},
url = {http://papers.nips.cc/paper/1856-gaussianization.pdf},
year = {2001}
}
@article{Smith2011,
abstract = {There is great interest in estimating brain "networks" from FMRI data. This is often attempted by identifying a set of functional "nodes" (e.g., spatial ROIs or ICA maps) and then conducting a connectivity analysis between the nodes, based on the FMRI timeseries associated with the nodes. Analysis methods range from very simple measures that consider just two nodes at a time (e.g., correlation between two nodes' timeseries) to sophisticated approaches that consider all nodes simultaneously and estimate one global network model (e.g., Bayes net models). Many different methods are being used in the literature, but almost none has been carefully validated or compared for use on FMRI timeseries data. In this work we generate rich, realistic simulated FMRI data for a wide range of underlying networks, experimental protocols and problematic confounds in the data, in order to compare different connectivity estimation approaches. Our results show that in general correlation-based approaches can be quite successful, methods based on higher-order statistics are less sensitive, and lag-based approaches perform very poorly. More specifically: there are several methods that can give high sensitivity to network connection detection on good quality FMRI data, in particular, partial correlation, regularised inverse covariance estimation and several Bayes net methods; however, accurate estimation of connection directionality is more difficult to achieve, though Patel's ??can be reasonably successful. With respect to the various confounds added to the data, the most striking result was that the use of functionally inaccurate ROIs (when defining the network nodes and extracting their associated timeseries) is extremely damaging to network estimation; hence, results derived from inappropriate ROI definition (such as via structural atlases) should be regarded with great caution. ?? 2010 Elsevier Inc.},
author = {Smith, Stephen M. and Miller, Karla L. and Salimi-Khorshidi, Gholamreza and Webster, Matthew and Beckmann, Christian F. and Nichols, Thomas E. and Ramsey, Joseph D. and Woolrich, Mark W.},
doi = {10.1016/j.neuroimage.2010.08.063},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Smith et al. - 2011 - Network modelling methods for FMRI.pdf:pdf},
isbn = {1095-9572 (Electronic)$\backslash$r1053-8119 (Linking)},
issn = {10538119},
journal = {NeuroImage},
keywords = {Causality,FMRI,Network modelling},
number = {2},
pages = {875--891},
pmid = {20817103},
publisher = {Elsevier Inc.},
title = {{Network modelling methods for FMRI}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2010.08.063},
volume = {54},
year = {2011}
}
@inproceedings{Hyttinen2015,
address = {Amsterdam},
annote = {Haven't read it yet, but seems interesting to think about this approach.

This is especially important if we don't have some ground truth on what are the confounds and what are predictors.},
author = {Hyttinen, Antti and Eberhardt, Frederick and Matti, J},
booktitle = {Proceedings of the 31st Conference on Uncertainty in Artificial Intelligence},
editor = {Meila, Marina and Heskes, Tom},
file = {:Users/anavarro/Documents/hyttinen2015.pdf:pdf},
isbn = {9780000000002},
pages = {395--404},
publisher = {AUAI Press},
title = {{Do-calculus when the True Graph Is Unknown}},
year = {2015}
}
@techreport{Smith2016,
address = {Oxford, UK},
annote = {This is helpful to understand the UK Biobank data},
author = {Smith, Stephen M. and Almagro, Fidel Alfaro and Miller, Karla L.},
file = {:Users/anavarro/Documents/brain{\_}mri.pdf:pdf},
institution = {University of Oxford},
number = {January},
pages = {1--31},
title = {{UK Biobank Imaging Documentation}},
url = {data /vols/Data/HCP/BBUK/workspace3b.mat script /home/fs0/steve/BB{\_}README},
year = {2016}
}
@article{Le2000,
abstract = {Discovering causal relationships from data is the ultimate goal of many research areas. Constraint based causal exploration algorithms, such as PC, FCI, RFCI, PC-simple, IDA and Joint-IDA have achieved significant progress and have many applications. A common problem with these methods is the high computational complexity, which hinders their applications in real world high dimensional datasets, e.g gene expression datasets. In this paper, we present an R package, ParallelPC, that includes the parallelised versions of these causal exploration algorithms. The parallelised algorithms help speed up the procedure of experimenting big datasets and reduce the memory used when running the algorithms. The package is not only suitable for super-computers or clusters, but also convenient for researchers using personal computers with multi core CPUs. Our experiment results on real world datasets show that using the parallelised algorithms it is now practical to explore causal relationships in high dimensional datasets with thousands of variables in a single multicore computer. ParallelPC is available in CRAN repository at https://cran.r-project.org/web/packages/ParallelPC/index.html.},
archivePrefix = {arXiv},
arxivId = {arXiv:1510.03042v1},
author = {Le, Thuc D and Hoang, Tao and Li, Jiuyong and Liu, Lin and Hu, Shu},
eprint = {arXiv:1510.03042v1},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Le et al. - 2000 - ParallelPC an R package for efficient constraint based causal exploration.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {Bayesian networks,Causality discovery,Constraint-based methods,Parallel computing},
pages = {1--48},
title = {{ParallelPC: an R package for efficient constraint based causal exploration}},
volume = {1},
year = {2000}
}
@book{Spirtes2000,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Spirtes, Peter L. and Glymour, Clark and Scheines, Richard},
doi = {10.1017/CBO9781107415324.004},
edition = {2nd},
eprint = {arXiv:1011.1669v3},
file = {:Users/anavarro/Library/Application Support/Mendeley Desktop/Downloaded/Spirtes, Glymour, Scheines - 2000 - Causation, Prediction, and Search.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
keywords = {icle},
pmid = {25246403},
publisher = {MIT Press},
title = {{Causation, Prediction, and Search}},
year = {2000}
}
@article{Didelez2007,
annote = {A simple introduction to instrumental variables and what biologists call

Mendellian Randomisation

showing it's just a simple Graphical Model with do-calculus (see either Pearl's book or his more recent keynote talk @ UAI ).},
author = {Didelez, V and Sheehan, N A},
file = {:Users/anavarro/Documents/didelez2007.pdf:pdf},
journal = {Statistical Methods in Medical Research},
number = {4},
pages = {309--330},
title = {{Mendelian randomization as an instrumental variable approach to causal inference}},
volume = {16},
year = {2007}
}
@inproceedings{Pearl2012,
abstract = {The do-calculus was developed in 1995 to facilitate the identification of causal effects in non-parametric models. The completeness proofs of [Huang and Valtorta, 2006] and [Shpitser and Pearl, 2006] and the graphical criteria of [Tian and Shpitser, 2010] have laid this identification problem to rest. Recent explorations unveil the usefulness of the do-calculus in three additional areas: mediation analysis [Pearl, 2012], transportability [Pearl and Bareinboim, 2011] and metasynthesis. Meta-synthesis (freshly coined) is the task of fusing empirical results from several diverse studies, conducted on heterogeneous populations and under different conditions, so as to synthesize an estimate of a causal relation in some target environment, potentially different from those under study. The talk surveys these results with emphasis on the challenges posed by meta-synthesis. For background material, see http://bayes.cs.ucla.edu/csl{\_}papers.html},
address = {Catalina},
annote = {Refresher on Pearl's do-calculus.

It is a quick fix for not going through his entire book.},
archivePrefix = {arXiv},
arxivId = {1210.4852},
author = {Pearl, Judea},
booktitle = {Proceedings of the Twenty-Eighth Conference on Uncertainty in Artificial Intelligence},
editor = {de Freitas, Nando and Murphy, Kevin},
eprint = {1210.4852},
file = {:Users/anavarro/Documents/pearl2012.pdf:pdf},
isbn = {9780974903989},
issn = {0000-0000},
number = {August},
pages = {4--11},
title = {{The Do-Calculus Revisited}},
year = {2012}
}
@article{Aliferis2010,
abstract = {We present an algorithmic framework for learning local causal structure around target variables of interest in the form of direct causes/effects and Markov blankets applicable to very large data sets with relatively small samples. The selected feature sets can be used for causal discovery and clas-sification. The framework (Generalized Local Learning, or GLL) can be instantiated in numerous ways, giving rise to both existing state-of-the-art as well as novel algorithms. The resulting algo-rithms are sound under well-defined sufficient conditions. In a first set of experiments we evaluate several algorithms derived from this framework in terms of predictivity and feature set parsimony and compare to other local causal discovery methods and to state-of-the-art non-causal feature se-lection methods using real data. A second set of experimental evaluations compares the algorithms in terms of ability to induce local causal neighborhoods using simulated and resimulated data and examines the relation of predictivity with causal induction performance. Our experiments demonstrate, consistently with causal feature selection theory, that local causal feature selection methods (under broad assumptions encompassing appropriate family of distribu-c Constantin F. Aliferis, Alexander Statnikov, Ioannis Tsamardinos, Subramani Mani and Xenofon D. Koutsoukos. ALIFERIS, STATNIKOV, TSAMARDINOS, MANI AND KOUTSOUKOS tions, types of classifiers, and loss functions) exhibit strong feature set parsimony, high predictivity and local causal interpretability. Although non-causal feature selection methods are often used in practice to shed light on causal relationships, we find that they cannot be interpreted causally even when they achieve excellent predictivity. Therefore we conclude that only local causal techniques should be used when insight into causal structure is sought. In a companion paper we examine in depth the behavior of GLL algorithms, provide extensions, and show how local techniques can be used for scalable and accurate global causal graph learning.},
author = {Aliferis, Constantin F. and Statnikov, Alexander and Tsamardinos, Ioannis and Mani, Subramani and Koutsoukos, Xenofon D.},
file = {:Users/anavarro/Documents/aliferis10a.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {Markov blanket induction,causal structure learning,classification,feature selection,learning of Bayesian networks,local causal discovery},
pages = {171--234},
pmid = {20164485},
title = {{Local Causal and Markov Blanket Induction for Causal Discovery and Feature Selection for Classification Part I: Algorithms and Empirical Evaluation Ioannis Tsamardinos}},
volume = {11},
year = {2010}
}
